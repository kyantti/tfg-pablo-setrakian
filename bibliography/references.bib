% Bibliography optimized for citation order in the document
% Ordered by first appearance and frequency of citations

% First cited - Precision Agriculture (Chapter 1 and 2)
@article{CISTERNAS2020105626,
title = {Systematic literature review of implementations of precision agriculture},
journal = {Computers and Electronics in Agriculture},
volume = {176},
pages = {105626},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105626},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920312357},
author = {Isabel Cisternas and Ignacio Velásquez and Angélica Caro and Alfonso Rodríguez},
keywords = {Precision agriculture, Systematic literature review, Information technologies, Precision agriculture implementations},
abstract = {Agriculture production highly depends on water and soil factors which increasingly need to be utilized efficiently. Precision agriculture, through the set of information technologies that it uses, allows to effectively manage these resources. This work aims to gather the existing knowledge on technologies used in precision agriculture and ways to discern the most appropriate one for different contexts in agricultural processes. A systematic literature review is performed to identify precision agriculture implementations and to answer questions such as the type of technologies used, criteria for their comparison and selection, and the existence of frameworks that help to decide what technologies to implement. A total of 3,949 publications were reviewed, of which 259 addressed the posed research questions. The findings are that remote sensors are the most used technology, the required knowledge is an important criterion for deciding to implement precision agriculture, and no framework was found that guides its implementation.}
}

% HSI systematic review in agriculture - frequently cited in Chapter 2
@article{KHAN2022101678,
title = {A systematic review on hyperspectral imaging technology with a machine and deep learning methodology for agricultural applications},
journal = {Ecological Informatics},
volume = {69},
pages = {101678},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101678},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122001285},
author = {Atiya Khan and Amol D. Vibhute and Shankar Mali and C.H. Patil},
keywords = {Hyperspectral imaging, Crop classification, Deep learning, Machine learning, Remote sensing, Precision agriculture},
abstract = {The globe's population is increasing day by day, which causes the severe problem of organic food for everyone. Farmers are becoming progressively conscious of the need to control numerous essential factors such as crop health, water or fertilizer use, and harmful diseases in the field. However, it is challenging to monitor agricultural activities. Therefore, precision agriculture is an important decision support system for food production and decision-making. Several methods and approaches have been used to support precision agricultural practices. The present study performs a systematic literature review on hyperspectral imaging technology and the most advanced deep learning and machine learning algorithm used in agriculture applications to extract and synthesize the significant datasets and algorithms. We reviewed legal studies carefully, highlighted hyperspectral datasets, focused on the most methods used for hyperspectral applications in agricultural sectors, and gained insight into the critical problems and challenges in the hyperspectral data processing. According to our study, it has been found that the Hyperion hyperspectral, Landsat-8, and Sentinel 2 multispectral datasets were mainly used for agricultural applications. The most applied machine learning method was support vector machine and random forest. In addition, the deep learning-based Convolutional Neural Networks (CNN) model is mainly used for crop classification due to its high performance with hyperspectral datasets. The present review will be helpful to the new researchers working in the field of hyperspectral remote sensing for agricultural applications with a machine and deep learning methods.}
}


% Aflatoxin detection with hyperspectral - highly relevant to the main topic
@Article{agriengineering6040225,
AUTHOR = {Cruz-Carrasco, Cristian and Díaz-Álvarez, Josefa and Chávez de la O, Francisco and Sánchez-Venegas, Abel and Villegas Cortez, Juan},
TITLE = {Detection of Aspergillus flavus in Figs by Means of Hyperspectral Images and Deep Learning Algorithms},
JOURNAL = {AgriEngineering},
VOLUME = {6},
YEAR = {2024},
NUMBER = {4},
PAGES = {3969--3988},
URL = {https://www.mdpi.com/2624-7402/6/4/225},
ISSN = {2624-7402},
ABSTRACT = {Plant diseases cause economic losses and health risks, such as aflatoxins linked to liver cancer. These toxins, produced by fungi like Aspergillus flavus in figs, are often detected late through invasive methods or visual inspection. Since Spain, particularly Extremadura, is a key fig producer, alternative detection methods are essential to preventing aflatoxins in the food chain. The aim of this research is the early detection of Aspergillus flavus fungus using non-invasive techniques with hyperspectral imaging and applying artificial intelligence techniques, in particular deep learning. The images were taken after inoculation of the microtoxin using 3 different concentrations, related to three different classes and healthy figs (healthy controls). The analysis of the hyperspectral images was performed at the pixel level. Firstly, a fully connected neural network was used to analyze the spectral signature associated with each pixel; secondly, the wavelet transform was applied to each spectral signature. The resulting images were fed to a convolutional neural network. The hyperparameters of the proposed models were adjusted based on the parameter tuning process that was performed. The results are promising, with 83% accuracy, 82.75% recall, and 83.25% F1-measure for the fully connected neural network. The high F1-measure demonstrates that the model's performance is good. The model has a low incidence of false positives for samples that contain aflatoxin, while a higher number of false positives appears in healthy controls. Due to the presence of false negatives, this class also has a high recall. The convolutional neural network results, accuracy, recall, and F1 are 77.25%, indicating moderate model performance. Only class 3, with higher aflatoxin concentration, achieves high precision and low false positive incidence. Healthy controls exhibit a high presence of false negatives. In conclusion, we demonstrate the effectiveness of pixel-level analysis in identifying the presence of the fungus and the viability of the non-invasive techniques applied in improving food safety. Although further research is needed, in this study, the fully connected neural network model shows good performance with lower energy consumption.},
DOI = {10.3390/agriengineering6040225}
}


% HSI quality assessment review - frequently cited
@article{WIEME2022156,
title = {Application of hyperspectral imaging systems and artificial intelligence for quality assessment of fruit, vegetables and mushrooms: A review},
journal = {Biosystems Engineering},
volume = {222},
pages = {156-176},
year = {2022},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2022.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S1537511022001751},
author = {Jana Wieme and Kaveh Mollazade and Ioannis Malounas and Manuela Zude-Sasse and Ming Zhao and Aoife Gowen and Dimitrios Argyropoulos and Spyros Fountas and Jonathan {Van Beek}},
keywords = {Hyperspectral imaging, Fruit, Vegetables, Mushrooms, Artificial intelligence, Quality assessment},
abstract = {Over the last two decades, research in hyperspectral imaging has been increasing and its use in horticulture is expected to be spreading in the coming years. The emerging techniques are currently gaining interest of the research community. However, there are still challenges to the applicability. In this review we demonstrate that hyperspectral imaging can be used as an effective tool for fruit, vegetables and mushrooms in assessing quality parameters related to well defined variables that can be analysed in the laboratory, as well as complex properties such as maturity, ripeness, detection of biotic defects, physiological disorders, mechanical damages, and sensory quality. Therefore, this paper starts by giving an overview of the quality concept of produce, measuring principles, theory and analysis of hyperspectral imaging systems. Then, emerging techniques to monitor and assess quality parameters, both pre- and postharvest, are described, as well as applications of these are reviewed and discussed. Afterwards, this review proceeds by illustrating the current and potential use of artificial intelligence and its subdomains, machine learning and deep learning, for hyperspectral imaging analysis in horticulture. Lastly, some challenges and considerations for future research are highlighted, including improvement of data availability, possible solutions for an improved integration of artificial intelligence and the transfer of knowledge from research parameters to parameters relevant for industrial stakeholders.}
}

% Deep learning review - heavily cited in machine learning section  
@article{PAOLETTI2019279,
title = {Deep learning classifiers for hyperspectral imaging: A review},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {158},
pages = {279-317},
year = {2019},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619302187},
author = {M.E. Paoletti and J.M. Haut and J. Plaza and A. Plaza},
keywords = {Deep learning (DL), Hyperspectral imaging (HSI), Earth observation (EO), Classification},
abstract = {Advances in computing technology have fostered the development of new and powerful deep learning (DL) techniques, which have demonstrated promising results in a wide range of applications. Particularly, DL methods have been successfully used to classify remotely sensed data collected by Earth Observation (EO) instruments. Hyperspectral imaging (HSI) is a hot topic in remote sensing data analysis due to the vast amount of information comprised by this kind of images, which allows for a better characterization and exploitation of the Earth surface by combining rich spectral and spatial information. However, HSI poses major challenges for supervised classification methods due to the high dimensionality of the data and the limited availability of training samples. These issues, together with the high intraclass variability (and interclass similarity) –often present in HSI data– may hamper the effectiveness of classifiers. In order to solve these limitations, several DL-based architectures have been recently developed, exhibiting great potential in HSI data interpretation. This paper provides a comprehensive review of the current-state-of-the-art in DL for HSI classification, analyzing the strengths and weaknesses of the most widely used classifiers in the literature. For each discussed method, we provide quantitative results using several well-known and widely used HSI scenes, thus providing an exhaustive comparison of the discussed techniques. The paper concludes with some remarks and hints about future challenges in the application of DL techniques to HSI classification. The source codes of the methods discussed in this paper are available from: https://github.com/mhaut/hyperspectral_deeplearning_review.}
}

% Deep learning multidisciplinary review - frequently cited
@Article{jimaging5050052,
AUTHOR = {Signoroni, Alberto and Savardi, Mattia and Baronio, Annalisa and Benini, Sergio},
TITLE = {Deep Learning Meets Hyperspectral Image Analysis: A Multidisciplinary Review},
JOURNAL = {Journal of Imaging},
VOLUME = {5},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2313-433X/5/5/52},
PubMedID = {34460490},
ISSN = {2313-433X},
ABSTRACT = {Modern hyperspectral imaging systems produce huge datasets potentially conveying a great abundance of information; such a resource, however, poses many challenges in the analysis and interpretation of these data. Deep learning approaches certainly offer a great variety of opportunities for solving classical imaging tasks and also for approaching new stimulating problems in the spatial–spectral domain. This is fundamental in the driving sector of Remote Sensing where hyperspectral technology was born and has mostly developed, but it is perhaps even more true in the multitude of current and evolving application sectors that involve these imaging technologies. The present review develops on two fronts: on the one hand, it is aimed at domain professionals who want to have an updated overview on how hyperspectral acquisition techniques can combine with deep learning architectures to solve specific tasks in different application fields. On the other hand, we want to target the machine learning and computer vision experts by giving them a picture of how deep learning technologies are applied to hyperspectral data from a multidisciplinary perspective. The presence of these two viewpoints and the inclusion of application fields other than Remote Sensing are the original contributions of this review, which also highlights some potentialities and critical issues related to the observed development trends.},
DOI = {10.3390/jimaging5050052}
}

% HSI foundational work - cited for basic concepts
@article{article,
author = {Sahoo, Rabi and Ray, Shibendu and R, Manjunath},
year = {2015},
month = {03},
pages = {848-859},
title = {Hyperspectral remote sensing of agriculture},
volume = {108},
journal = {Current science}
}

% Plant disease detection with RGB - cited for RGB applications
@article{FERENTINOS2018311,
title = {Deep learning models for plant disease detection and diagnosis},
journal = {Computers and Electronics in Agriculture},
volume = {145},
pages = {311-318},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S0168169917311742},
author = {Konstantinos P. Ferentinos},
keywords = {Convolutional neural networks, Machine learning, Artificial intelligence, Plant disease identification, Pattern recognition},
abstract = {In this paper, convolutional neural network models were developed to perform plant disease detection and diagnosis using simple leaves images of healthy and diseased plants, through deep learning methodologies. Training of the models was performed with the use of an open database of 87,848 images, containing 25 different plants in a set of 58 distinct classes of [plant, disease] combinations, including healthy plants. Several model architectures were trained, with the best performance reaching a 99.53% success rate in identifying the corresponding [plant, disease] combination (or healthy plant). The significantly high success rate makes the model a very useful advisory or early warning tool, and an approach that could be further expanded to support an integrated plant disease identification system to operate in real cultivation conditions.}
}

% Semi-supervised dimensionality reduction - cited for feature selection
@article{HONG201935,
title = {Learning to propagate labels on graphs: An iterative multitask regression framework for semi-supervised hyperspectral dimensionality reduction},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {158},
pages = {35-49},
year = {2019},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619302199},
author = {Danfeng Hong and Naoto Yokoya and Jocelyn Chanussot and Jian Xu and Xiao Xiang Zhu},
keywords = {Dimensionality reduction, Graph learning, Hyperspectral image, Iterative, Label propagation, Multitask regression, Remote sensing, Semi-supervised},
abstract = {Hyperspectral dimensionality reduction (HDR), an important preprocessing step prior to high-level data analysis, has been garnering growing attention in the remote sensing community. Although a variety of methods, both unsupervised and supervised models, have been proposed for this task, yet the discriminative ability in feature representation still remains limited due to the lack of a powerful tool that effectively exploits the labeled and unlabeled data in the HDR process. A semi-supervised HDR approach, called iterative multitask regression (IMR), is proposed in this paper to address this need. IMR aims at learning a low-dimensional subspace by jointly considering the labeled and unlabeled data, and also bridging the learned subspace with two regression tasks: labels and pseudo-labels initialized by a given classifier. More significantly, IMR dynamically propagates the labels on a learnable graph and progressively refines pseudo-labels, yielding a well-conditioned feedback system. Experiments conducted on three widely-used hyperspectral image datasets demonstrate that the dimension-reduced features learned by the proposed IMR framework with respect to classification or recognition accuracy are superior to those of related state-of-the-art HDR approaches.}
}

% Spectral-spatial residual networks - cited for 3D CNN architectures
@article{Zhong,
author = {Zhong, Zilong and Li, Jonathan and Luo, Zhiming and Chapman, Michael},
year = {2017},
month = {10},
pages = {847-858},
title = {Spectral-Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework},
volume = {56},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
doi = {10.1109/TGRS.2017.2755542}
}

% Pioneer deep learning for HSI - cited for historical context
@article{chen2014deep,
author = {Chen, Yushi and Lin, Zhouhan and Zhao, Xing and Wang, Gang and Gu, Yanfeng},
year = {2014},
month = {06},
pages = {2094-2107},
title = {Deep Learning-Based Classification of Hyperspectral Data},
volume = {7},
journal = {Selected Topics in Applied Earth Observations and Remote Sensing, IEEE Journal of},
doi = {10.1109/JSTARS.2014.2329330}
}

@misc{lin2015microsoftcococommonobjects,
      title={Microsoft COCO: Common Objects in Context}, 
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1405.0312}, 
}

@misc{ravi2024sam2segmentimages,
      title={SAM 2: Segment Anything in Images and Videos}, 
      author={Nikhila Ravi and Valentin Gabeur and Yuan-Ting Hu and Ronghang Hu and Chaitanya Ryali and Tengyu Ma and Haitham Khedr and Roman Rädle and Chloe Rolland and Laura Gustafson and Eric Mintun and Junting Pan and Kalyan Vasudev Alwala and Nicolas Carion and Chao-Yuan Wu and Ross Girshick and Piotr Dollár and Christoph Feichtenhofer},
      year={2024},
      eprint={2408.00714},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.00714}, 
}

@article{liu2023grounding,
  title={Grounding dino: Marrying dino with grounded pre-training for open-set object detection},
  author={Liu, Shilong and Zeng, Zhaoyang and Ren, Tianhe and Li, Feng and Zhang, Hao and Yang, Jie and Li, Chunyuan and Yang, Jianwei and Su, Hang and Zhu, Jun and others},
  journal={arXiv preprint arXiv:2303.05499},
  year={2023}
}

@misc{ren2024grounding,
      title={Grounding DINO 1.5: Advance the "Edge" of Open-Set Object Detection}, 
      author={Tianhe Ren and Qing Jiang and Shilong Liu and Zhaoyang Zeng and Wenlong Liu and Han Gao and Hongjie Huang and Zhengyu Ma and Xiaoke Jiang and Yihao Chen and Yuda Xiong and Hao Zhang and Feng Li and Peijun Tang and Kent Yu and Lei Zhang},
      year={2024},
      eprint={2405.10300},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{ren2024grounded,
      title={Grounded SAM: Assembling Open-World Models for Diverse Visual Tasks}, 
      author={Tianhe Ren and Shilong Liu and Ailing Zeng and Jing Lin and Kunchang Li and He Cao and Jiayu Chen and Xinyu Huang and Yukang Chen and Feng Yan and Zhaoyang Zeng and Hao Zhang and Feng Li and Jie Yang and Hongyang Li and Qing Jiang and Lei Zhang},
      year={2024},
      eprint={2401.14159},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{kirillov2023segany,
  title={Segment Anything}, 
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
  journal={arXiv:2304.02643},
  year={2023}
}

@misc{jiang2024trex2,
      title={T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy}, 
      author={Qing Jiang and Feng Li and Zhaoyang Zeng and Tianhe Ren and Shilong Liu and Lei Zhang},
      year={2024},
      eprint={2403.14610},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@misc{socher2013zeroshotlearningcrossmodaltransfer,
      title={Zero-Shot Learning Through Cross-Modal Transfer}, 
      author={Richard Socher and Milind Ganjoo and Hamsa Sridhar and Osbert Bastani and Christopher D. Manning and Andrew Y. Ng},
      year={2013},
      eprint={1301.3666},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1301.3666}, 
}

@misc{anaconda,
  title={Anaconda Software Distribution},
  url={https://docs.anaconda.com/},
  journal={Anaconda Documentation},
  version={Vers. 2-2.4.0}, 
  publisher={Anaconda Inc.},
  year={2020}
}

@misc{uv2024github,
  title = {UV: An Extremely Fast Python Package Installer and Resolver},
  author = {{Astral}},
  year = {2024},
  note = {GitHub Repository. Disponible en: https://github.com/astral-sh/uv},
  url = {https://github.com/astral-sh/uv}
}

@book{van1995python, 
  title={Python tutorial}, 
  author={Van Rossum, Guido and Drake Jr, Fred L}, 
  year={1995}, 
  publisher={Centrum voor Wiskunde en Informatica Amsterdam, The Netherlands} 
}

@article{behnel2011cython,
  title={Cython: The best of both worlds},
  author={Behnel, Stefan and Bradshaw, Robert and Citro, Craig and Dalcin, Lisandro and Seljebotn, Dag Sverre and Smith, Kurt},
  journal={Computing in Science \& Engineering},
  volume={13},
  number={2},
  pages={31--39},
  year={2011},
  publisher={IEEE}
}

@inproceedings{matsakis2014rust,
  title={The rust language},
  author={Matsakis, Nicholas D and Klock II, Felix S},
  booktitle={ACM SIGAda Ada Letters},
  volume={34},
  pages={103--104},
  year={2014},
  organization={ACM}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@ARTICLE{2020NumPy-Array,
  author  = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, Stéfan J and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and Fernández del Río, Jaime and Wiebe, Mark and Peterson, Pearu and Gérard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
  title   = {Array programming with {NumPy}},
  journal = {Nature},
  year    = {2020},
  volume  = {585},
  pages   = {357–362},
  doi     = {10.1038/s41586-020-2649-2}
}

@ARTICLE{2020SciPy-NMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and {van der Walt}, St{\'e}fan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C J and Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@inproceedings{sklearn_api,
  author    = {Lars Buitinck and Gilles Louppe and Mathieu Blondel and
               Fabian Pedregosa and Andreas Mueller and Olivier Grisel and
               Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort
               and Jaques Grobler and Robert Layton and Jake VanderPlas and
               Arnaud Joly and Brian Holt and Ga{\"{e}}l Varoquaux},
  title     = {{API} design for machine learning software: experiences from the scikit-learn
               project},
  booktitle = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
  year      = {2013},
  pages = {108--122},
}

@software{thomas_boggs_2022_7135091,
  author       = {Thomas Boggs and
                  Don March and
                  kormang and
                  Lewis John McGibbney and
                  François Magimel and
                  Gemma Mason and
                  Kirby Banman and
                  Mohamad Jouni (Luffy Uzumaki) and
                  Rajath Kumar and
                  The Gitter Badger and
                  Tomi Aarnio and
                  Wanli Wang and
                  kidpixo},
  title        = {spectralpython/spectral: Spectral Python (SPy)
                   0.23.1
                  },
  month        = oct,
  year         = 2022,
  publisher    = {Zenodo},
  version      = {0.23.1},
  doi          = {10.5281/zenodo.7135091},
  url          = {https://doi.org/10.5281/zenodo.7135091},
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@software{Roboflow_Supervision,
author = {Roboflow},
license = {MIT},
title = {{Supervision}},
url = {https://github.com/roboflow/supervision}
}

@article{Welsh2018,
  author       = {Welsh, C. M. and Fullard, N. and Proctor, C. J. and Martinez-Guimera, A. and Isfort, R. J. and Bascom, C. C. and Tasseff, R. and Przyborski, S. A. and Shanley, D. P.},
  title        = {PyCoTools: a Python toolbox for COPASI},
  journal      = {Bioinformatics},
  volume       = {34},
  number       = {21},
  pages        = {3702--3710},
  year         = {2018},
}

@article{Hoops2006,
  author       = {Hoops, S. and Sahle, S. and Gauges, R. and Lee, C. and Pahle, J. and Simus, N. and Singhal, M. and Xu, L. and Mendes, P. and Kummer, U.},
  title        = {COPASI—a complex pathway simulator},
  journal      = {Bioinformatics},
  volume       = {22},
  number       = {24},
  pages        = {3067--3074},
  year         = {2006},
}

@article{Medley2018,
  author       = {Medley, J. K. and Choi, K. and König, M. and Smith, L. and Gu, S. and Hellerstein, J. and Sealfon, S. C. and Sauro, H. M.},
  title        = {Tellurium notebooks—An environment for reproducible dynamical modeling in systems biology},
  journal      = {PLOS Computational Biology},
  volume       = {14},
  number       = {6},
  pages        = {e1006220},
  year         = {2018},
}

@article{DEAP_JMLR2012,
    author    = " F\'elix-Antoine Fortin and Fran\c{c}ois-Michel {De Rainville} and Marc-Andr\'e Gardner and Marc Parizeau and Christian Gagn\'e ",
    title     = { {DEAP}: Evolutionary Algorithms Made Easy },
    pages     = { 2171--2175 },
    volume    = { 13 },
    month     = { jul },
    year      = { 2012 },
    journal   = { Journal of Machine Learning Research }
}

@techreport{crockford2006application,
  title={The application/json media type for javascript object notation (json)},
  author={Crockford, Douglas},
  year={2006},
  institution={Internet Engineering Task Force (IETF)},
  number={RFC 4627}
}

@misc{micikevicius2018mixedprecisiontraining,
      title={Mixed Precision Training}, 
      author={Paulius Micikevicius and Sharan Narang and Jonah Alben and Gregory Diamos and Erich Elsen and David Garcia and Boris Ginsburg and Michael Houston and Oleksii Kuchaiev and Ganesh Venkatesh and Hao Wu},
      year={2018},
      eprint={1710.03740},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1710.03740}, 
}
@INPROCEEDINGS{8877411,
  author={Agrawal, Ankur and Mueller, Silvia M. and Fleischer, Bruce M. and Sun, Xiao and Wang, Naigang and Choi, Jungwook and Gopalakrishnan, Kailash},
  booktitle={2019 IEEE 26th Symposium on Computer Arithmetic (ARITH)}, 
  title={DLFloat: A 16-b Floating Point Format Designed for Deep Learning Training and Inference}, 
  year={2019},
  volume={},
  number={},
  pages={92-95},
  keywords={Training;Deep learning;Hardware;Dynamic range;Adders;Engines;Image recognition;reduced precision computation, floating point, machine learning, deep learning},
  doi={10.1109/ARITH.2019.00023}}

  @misc{he2015deepresiduallearningimage,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385}, 
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}