Layer,Output Format,Training Settings
Linear (0),128,"131,200"
ReLU (1),128,-
BatchNorm1d (2),128,256
Dropout (3),128,-
Linear (4),64,"8,256"
ReLU (5),64,-
Dropout (6),64,-
Linear (7),4,260
Total,-,139972
